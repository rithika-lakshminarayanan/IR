{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bitenvvenv7533db0592054ba080cdf2f4c2630703",
   "display_name": "Python 3.8.1 64-bit ('env': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_elasticsearch():\n",
    "    _es = None\n",
    "    _es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "    if _es.ping():\n",
    "        print('Yay Connected')\n",
    "    else:\n",
    "        print('Awww it could not connect!')\n",
    "    return _es\n",
    "if __name__ == '__main__':\n",
    "  logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Yay Connected\n"
    }
   ],
   "source": [
    "es = connect_elasticsearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Query File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_file_path = \"D:\\\\CS 6200\\\\AP_DATA\\\\query_desc.51-100.short.txt\"\n",
    "queries = dict()\n",
    "with open(query_file_path) as f:\n",
    "    for line in f:\n",
    "        if len(line.strip()) > 0:\n",
    "            query_no = re.search(r'\\d+', line).group()\n",
    "            line = line.lstrip('0123456789.- ')\n",
    "            queries[query_no] = line.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_relevant_terms = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'85': ['corrupt', 'bribe'], '59': ['thunderstorm', 'storm'], '56': ['prime', 'minist'], '71': ['troop', 'soldier'], '64': ['parti', 'leader'], '62': ['militari', 'coup'], '93': ['nation', 'presid'], '99': ['iran', 'contra'], '58': ['rail', 'railroad'], '77': ['poach', 'poacher'], '54': ['orbit', 'nasa'], '87': ['alleg', 'case'], '94': ['crime', 'convict'], '100': ['high', 'regul'], '89': ['invest', 'investor'], '61': ['iran', 'contra'], '95': ['comput', 'softwar'], '68': ['employe', 'worker'], '57': ['mci', \"mci'\"], '97': ['fiber', 'optic'], '98': ['fiber', 'optic'], '60': ['pai', 'salari'], '80': ['presidenti', 'candid'], '63': ['machin', 'chip'], '91': ['scientist', 'militari']}\n"
    }
   ],
   "source": [
    "for key in queries:\n",
    "    relevant_terms = dict()\n",
    "    analyzerTokens = es.indices.analyze(index = \"assignment1\", body = {\"tokenizer\" : \"standard\", \"filter\" : [\"lowercase\", \"my_stemmer\"], \"text\" : queries[key]})\n",
    "\n",
    "    query_words = []\n",
    "\n",
    "    for token in analyzerTokens[\"tokens\"]:\n",
    "        query_words.append(token[\"token\"])\n",
    "\n",
    "    for word in query_words:\n",
    "\n",
    "        statistics = es.search(index = \"assignment1\", body={\"query\" : {\"terms\" : {\"text\" : [word]}},\n",
    "    \"aggregations\" : {\"significantCrimeTypes\" : {\"significant_terms\" : {\"field\" : \"text\"}}},\"size\": 0})\n",
    "        \n",
    "        if len(statistics[\"aggregations\"][\"significantCrimeTypes\"][\"buckets\"])>0:\n",
    "            for term in statistics[\"aggregations\"][\"significantCrimeTypes\"][\"buckets\"]:\n",
    "                if term[\"key\"] not in relevant_terms.keys():\n",
    "                    relevant_terms[term[\"key\"]] = 1\n",
    "                else:\n",
    "                    relevant_terms[term[\"key\"]] += 1\n",
    "    sorted_d = dict( sorted(relevant_terms.items(), key=operator.itemgetter(1),reverse=True))\n",
    "    sortedKeys = list(sorted_d)\n",
    "\n",
    "    query_relevant_terms[key] = sortedKeys[:2]   \n",
    "print(query_relevant_terms)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outF = open(\"D:\\\\CS 6200\\\\AP_DATA\\\\queries_pr2.txt\", \"a\")\n",
    "for key in queries:\n",
    "    string = \"\"\n",
    "    for i in range(0, len(query_relevant_terms[key])):\n",
    "        string += \" \"+query_relevant_terms[key][i]\n",
    "    modified_query = queries[key] +string\n",
    "    line = str(key) + \". \" + modified_query + \"\\n\"\n",
    "    outF.write(line)\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}